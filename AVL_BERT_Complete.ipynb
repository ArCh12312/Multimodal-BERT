{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a3f6ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_loader import IEMOCAPLoader\n",
    "\n",
    "TRANSCRIPT_DIR = \"C:\\\\Users\\\\aryan\\\\Documents\\\\Study\\\\Research\\\\IEMOCAP_full_release\\\\Session1\\\\dialog\\\\transcriptions\"\n",
    "AUDIO_DIR = \"C:\\\\Users\\\\aryan\\\\Documents\\\\Study\\\\Research\\\\Audio_Output\"\n",
    "VIDEO_DIR = \"C:\\\\Users\\\\aryan\\\\Documents\\\\Study\\\\Research\\\\Video_Output\"\n",
    "LABEL_FILE = \"C:\\\\Users\\\\aryan\\\\Documents\\\\Study\\\\Research\\\\scene_emotions.csv\"\n",
    "\n",
    "loader = IEMOCAPLoader(TRANSCRIPT_DIR, AUDIO_DIR, VIDEO_DIR, LABEL_FILE)\n",
    "dataset = loader.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77475a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 151 scenes.\n",
      "Sample entry: {'scene_id': 'Ses01F_impro01', 'transcript': \"Excuse me.\\nDo you have your forms?\\nYeah.\\nLet me see them.\\nIs there a problem?\\nWho told you to get in this line?\\nYou did.\\nYou were standing at the beginning and you directed me.\\nOkay. But I didn't tell you to get in this line if you are filling out this particular form.\\nWell what's the problem?  Let me change it.\\nThis form is a Z.X.four.\\nYou can't--  This is not the line for Z.X.four.  If you're going to fill out the Z.X.four, you need to have a different form of ID.\\nWhat?  I'm getting an ID.  This is why I'm here.  My wallet was stolen.\\nNo. I need another set of ID to prove this is actually you.\\nHow am I supposed to get an ID without an ID?  How does a person get an ID in the first place?\\nI don't know.  But I need an ID to pass this form along.  I can't just send it along without an ID.\\nI'm here to get an ID.\\nNo.  I need another ID, a separate one.\\nLike what?  Like a birth certificate?\\nA birth certificate, a passport...a student ID; didn't you go to school?  Anything?\\nWho the hell has a birth certificate?\\nYes but my wallet was stolen, I don't have anything.  I don't have any credit cards, I don't have my ID.  Don't you have things on file here?\\nYeah.  We keep it on file, but we need an ID to access that file.\\nThat's out of control.\\nI don't understand why this is so complicated for people when they get here.  It's just a simple form.  I just need an ID.\\nHow long have you been working here?\\nActually too long.\\nClearly.  You know, do you have like a supervisor or something?\\nYeah.  Do you want to see my supervisor?  Huh? Yeah.  Do you want to see my supervisor?  Fine.  I'll be right back.\\nThat would - I would appreciate that.  Yeah.\", 'audio_path': 'C:\\\\Users\\\\aryan\\\\Documents\\\\Study\\\\Research\\\\Audio_Output\\\\Ses01F_impro01.npy', 'video_path': 'C:\\\\Users\\\\aryan\\\\Documents\\\\Study\\\\Research\\\\Video_Output\\\\Ses01F_impro01.npy', 'label': 'Frustration'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(dataset)} scenes.\")\n",
    "print(\"Sample entry:\", dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d1d8b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_embedding import BERTFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93870573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features shape: torch.Size([151, 125, 768])\n"
     ]
    }
   ],
   "source": [
    "# Extract just the transcript texts\n",
    "texts = [item[\"transcript\"] for item in dataset]\n",
    "\n",
    "extractor = BERTFeatureExtractor()\n",
    "text_embeddings = extractor.extract_features(texts)\n",
    "\n",
    "print(\"Extracted features shape:\", text_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc1e074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_embedding_paths = [item[\"video_path\"] for item in dataset]\n",
    "audio_embedding_paths = [item[\"audio_path\"] for item in dataset]\n",
    "video_embeddings = []\n",
    "audio_embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9120f44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded video embeddings\n",
      "\n",
      "Loaded audio embeddings\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "for path in video_embedding_paths:\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            embedding = np.load(path)\n",
    "            video_embeddings.append(embedding)\n",
    "            # print(f\"Loaded video embedding from: {path} (Shape: {embedding.shape})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading video embedding from {path}: {e}\")\n",
    "    else:\n",
    "        print(f\"Video embedding file not found: {path}\")\n",
    "print(\"\\nLoaded video embeddings\")\n",
    "\n",
    "for path in audio_embedding_paths:\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            embedding = np.load(path)\n",
    "            audio_embeddings.append(embedding)\n",
    "            # print(f\"Loaded audio embedding from: {path} (Shape: {embedding.shape})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading audio embedding from {path}: {e}\")\n",
    "    else:\n",
    "        print(f\"Audio embedding file not found: {path}\")\n",
    "print(\"\\nLoaded audio embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71da22a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully loaded 151 video embeddings.\n",
      "Successfully loaded 151 audio embeddings.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSuccessfully loaded {len(video_embeddings)} video embeddings.\")\n",
    "print(f\"Successfully loaded {len(audio_embeddings)} audio embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "180b43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_embeddings = torch.from_numpy(np.stack(video_embeddings))\n",
    "audio_embeddings = torch.from_numpy(np.stack(audio_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84a9b124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([151, 256, 768])\n",
      "torch.Size([151, 128, 768])\n"
     ]
    }
   ],
   "source": [
    "print(video_embeddings.shape)\n",
    "print(audio_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "688a0486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e57c32d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83a4a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_embedding = model.embeddings.word_embeddings(torch.tensor([tokenizer.cls_token_id]))\n",
    "sep_embedding = model.embeddings.word_embeddings(torch.tensor([tokenizer.sep_token_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6494befb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the CLS embedding: torch.Size([1, 768])\n",
      "Shape of the SEP embedding: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the CLS embedding:\", cls_embedding.shape)\n",
    "print(\"Shape of the SEP embedding:\", sep_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "312b0025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_modalities(cls_token, sep_token, video_tensor, audio_tensor, text_tensor):\n",
    "    fused = []\n",
    "    for v, a, t in zip(video_tensor, audio_tensor, text_tensor):\n",
    "        segments = [\n",
    "            cls_token,  # (1, 768)\n",
    "            v,          # (v_len, 768)\n",
    "            sep_token,  # (1, 768)\n",
    "            a,          # (a_len, 768)\n",
    "            sep_token,  # (1, 768)\n",
    "            t          # (t_len, 768)\n",
    "        ]\n",
    "        fused.append(torch.cat(segments, dim=0))  # (total_len, 768)\n",
    "\n",
    "    return fused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bb887a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_embeddings = concatenate_modalities(cls_embedding, sep_embedding, video_embeddings, audio_embeddings, text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00cc00ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 768])\n"
     ]
    }
   ],
   "source": [
    "print(fused_embeddings[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d19347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Dataset class\n",
    "# ----------------------------\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        \"\"\"\n",
    "        embeddings: torch.Tensor [num_samples, 512, 768]\n",
    "        labels: torch.Tensor [num_samples]\n",
    "        \"\"\"\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "        print(f\"Dataset initialized with {len(self.embeddings)} samples, {len(self.labels)} labels\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed54ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Model class\n",
    "# ----------------------------\n",
    "class BertEmbeddingClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(768),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(768, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs_embeds):\n",
    "        \"\"\"\n",
    "        inputs_embeds: [batch_size, 512, 768]\n",
    "        \"\"\"\n",
    "        outputs = self.bert(inputs_embeds=inputs_embeds)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]  # CLS token embedding\n",
    "        logits = self.classifier(cls_embedding)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8484e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Training and evaluation functions\n",
    "# ----------------------------\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_embeds, batch_labels in dataloader:\n",
    "        batch_embeds = batch_embeds.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch_embeds)\n",
    "        loss = criterion(logits, batch_labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_embeds, batch_labels in dataloader:\n",
    "            batch_embeds = batch_embeds.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            logits = model(batch_embeds)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "    return all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce140bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      " scene_emotion\n",
      "Frustration      61\n",
      "Excited          31\n",
      "Neutral state    28\n",
      "Sadness          17\n",
      "Anger            10\n",
      "Happiness         4\n",
      "Name: count, dtype: int64\n",
      "Classes: ['Anger' 'Excited' 'Frustration' 'Happiness' 'Neutral state' 'Sadness']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the label file\n",
    "df = pd.read_csv(\"C:/Users/aryan/Documents/Study/Research/scene_emotions.csv\")  # columns: scene_id, scene_emotion\n",
    "\n",
    "# Print class distribution\n",
    "print(\"Class distribution:\\n\", df['scene_emotion'].value_counts())\n",
    "\n",
    "# Create label encoder to convert emotion strings to integer classes\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['scene_emotion'])\n",
    "\n",
    "print(\"Classes:\", label_encoder.classes_)\n",
    "labels_tensor = torch.tensor(df['label'].values, dtype=torch.long)\n",
    "\n",
    "embeddings_tensor = torch.stack(fused_embeddings).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd89617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4adfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "--- Fold 1 ---\n",
      "Dataset initialized with 120 samples, 120 labels\n",
      "Dataset initialized with 31 samples, 31 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Weighted F1-score: 0.4812\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Anger       0.50      0.50      0.50         2\n",
      "      Excited       0.57      0.57      0.57         7\n",
      "  Frustration       0.59      0.77      0.67        13\n",
      "    Happiness       0.00      0.00      0.00         1\n",
      "Neutral state       0.33      0.20      0.25         5\n",
      "      Sadness       0.00      0.00      0.00         3\n",
      "\n",
      "     accuracy                           0.52        31\n",
      "    macro avg       0.33      0.34      0.33        31\n",
      " weighted avg       0.46      0.52      0.48        31\n",
      "\n",
      "\n",
      "--- Fold 2 ---\n",
      "Dataset initialized with 121 samples, 121 labels\n",
      "Dataset initialized with 30 samples, 30 labels\n",
      "Fold 2 Weighted F1-score: 0.6182\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Anger       1.00      0.50      0.67         2\n",
      "      Excited       0.83      0.83      0.83         6\n",
      "  Frustration       0.64      0.58      0.61        12\n",
      "    Happiness       0.00      0.00      0.00         1\n",
      "Neutral state       0.40      0.40      0.40         5\n",
      "      Sadness       0.57      1.00      0.73         4\n",
      "\n",
      "     accuracy                           0.63        30\n",
      "    macro avg       0.57      0.55      0.54        30\n",
      " weighted avg       0.63      0.63      0.62        30\n",
      "\n",
      "\n",
      "--- Fold 3 ---\n",
      "Dataset initialized with 121 samples, 121 labels\n",
      "Dataset initialized with 30 samples, 30 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Weighted F1-score: 0.5385\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Anger       0.00      0.00      0.00         2\n",
      "      Excited       1.00      0.50      0.67         6\n",
      "  Frustration       0.64      0.75      0.69        12\n",
      "    Happiness       0.00      0.00      0.00         0\n",
      "Neutral state       0.29      0.33      0.31         6\n",
      "      Sadness       0.50      0.50      0.50         4\n",
      "\n",
      "     accuracy                           0.53        30\n",
      "    macro avg       0.40      0.35      0.36        30\n",
      " weighted avg       0.58      0.53      0.54        30\n",
      "\n",
      "\n",
      "--- Fold 4 ---\n",
      "Dataset initialized with 121 samples, 121 labels\n",
      "Dataset initialized with 30 samples, 30 labels\n",
      "Fold 4 Weighted F1-score: 0.5935\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Anger       1.00      0.50      0.67         2\n",
      "      Excited       0.56      0.83      0.67         6\n",
      "  Frustration       0.62      0.83      0.71        12\n",
      "    Happiness       0.00      0.00      0.00         1\n",
      "Neutral state       0.50      0.17      0.25         6\n",
      "      Sadness       1.00      0.67      0.80         3\n",
      "\n",
      "     accuracy                           0.63        30\n",
      "    macro avg       0.61      0.50      0.52        30\n",
      " weighted avg       0.63      0.63      0.59        30\n",
      "\n",
      "\n",
      "--- Fold 5 ---\n",
      "Dataset initialized with 121 samples, 121 labels\n",
      "Dataset initialized with 30 samples, 30 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Weighted F1-score: 0.4486\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Anger       0.00      0.00      0.00         2\n",
      "      Excited       0.75      0.50      0.60         6\n",
      "  Frustration       0.60      0.75      0.67        12\n",
      "    Happiness       0.00      0.00      0.00         1\n",
      "Neutral state       0.17      0.17      0.17         6\n",
      "      Sadness       0.25      0.33      0.29         3\n",
      "\n",
      "     accuracy                           0.47        30\n",
      "    macro avg       0.29      0.29      0.29        30\n",
      " weighted avg       0.45      0.47      0.45        30\n",
      "\n",
      "\n",
      "Average Weighted F1-score across folds: 0.5360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Main\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Example dummy data: replace with your actual data\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    num_classes = len(set(labels_tensor))\n",
    "    num_samples = len(labels_tensor)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_f1_scores = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(embeddings_tensor, labels_tensor)):\n",
    "        print(f\"\\n--- Fold {fold+1} ---\")\n",
    "\n",
    "        train_embeds = embeddings_tensor[train_idx]\n",
    "        train_labels = labels_tensor[train_idx]\n",
    "        test_embeds = embeddings_tensor[test_idx]\n",
    "        test_labels = labels_tensor[test_idx]\n",
    "\n",
    "        train_dataset = EmbeddingDataset(train_embeds, train_labels)\n",
    "        test_dataset = EmbeddingDataset(test_embeds, test_labels)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "        model = BertEmbeddingClassifier(num_classes=num_classes).to(device)\n",
    "        optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(20):  # You can adjust this\n",
    "            train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "\n",
    "        all_labels, all_preds = evaluate(model, test_loader, device)\n",
    "        \n",
    "        # F1 Score\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        print(f\"Fold {fold+1} Weighted F1-score: {f1:.4f}\")\n",
    "        \n",
    "        # Accuracy\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        print(f\"Fold {fold+1} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Store metrics\n",
    "        all_accuracies.append(accuracy)\n",
    "        all_f1_scores.append(f1) \n",
    "\n",
    "        print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))\n",
    "\n",
    "    print(f\"\\nAverage Weighted F1-score across folds: {np.mean(all_accuracies):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
