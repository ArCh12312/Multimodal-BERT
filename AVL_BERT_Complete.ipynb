{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a3f6ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing audio or video for Ses01F_impro05, skipping.\n",
      "Missing audio or video for Ses01F_impro06, skipping.\n",
      "Missing audio or video for Ses01F_impro07, skipping.\n",
      "Missing audio or video for Ses01F_script01_1, skipping.\n",
      "Missing audio or video for Ses01F_script01_2, skipping.\n",
      "Missing audio or video for Ses01F_script01_3, skipping.\n",
      "Missing audio or video for Ses01F_script02_1, skipping.\n",
      "Missing audio or video for Ses01F_script02_2, skipping.\n",
      "Missing audio or video for Ses01F_script03_1, skipping.\n",
      "Missing audio or video for Ses01F_script03_2, skipping.\n",
      "Missing audio or video for Ses01M_impro01, skipping.\n",
      "Missing audio or video for Ses01M_impro02, skipping.\n",
      "Missing audio or video for Ses01M_impro03, skipping.\n",
      "Missing audio or video for Ses01M_impro04, skipping.\n",
      "Missing audio or video for Ses01M_impro05, skipping.\n",
      "Missing audio or video for Ses01M_impro06, skipping.\n",
      "Missing audio or video for Ses01M_impro07, skipping.\n",
      "Missing audio or video for Ses01M_script01_1, skipping.\n",
      "Missing audio or video for Ses01M_script01_2, skipping.\n",
      "Missing audio or video for Ses01M_script01_3, skipping.\n",
      "Missing audio or video for Ses01M_script02_1, skipping.\n",
      "Missing audio or video for Ses01M_script02_2, skipping.\n",
      "Missing audio or video for Ses01M_script03_1, skipping.\n",
      "Missing audio or video for Ses01M_script03_2, skipping.\n"
     ]
    }
   ],
   "source": [
    "from dataset_loader import IEMOCAPLoader\n",
    "\n",
    "TRANSCRIPT_DIR = \"C:\\\\Users\\\\aryan\\\\Documents\\\\Study\\\\Research\\\\IEMOCAP_full_release\\\\Session1\\\\dialog\\\\transcriptions\"\n",
    "AUDIO_DIR = \"C:\\\\Users\\\\aryan\\\\Documents\\\\Study\\\\Research\\\\Audio_Output\"\n",
    "VIDEO_DIR = \"C:\\\\Users\\\\aryan\\\\Documents\\\\Study\\\\Research\\\\Video_Output\"\n",
    "LABEL_FILE = \"C:\\\\Users\\\\aryan\\\\Documents\\\\Study\\\\Research\\\\scene_emotions.csv\"\n",
    "\n",
    "loader = IEMOCAPLoader(TRANSCRIPT_DIR, AUDIO_DIR, VIDEO_DIR, LABEL_FILE)\n",
    "dataset = loader.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77475a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 scenes.\n",
      "Sample entry: {'scene_id': 'Ses01F_impro01', 'transcript': \"Excuse me.\\nDo you have your forms?\\nYeah.\\nLet me see them.\\nIs there a problem?\\nWho told you to get in this line?\\nYou did.\\nYou were standing at the beginning and you directed me.\\nOkay. But I didn't tell you to get in this line if you are filling out this particular form.\\nWell what's the problem?  Let me change it.\\nThis form is a Z.X.four.\\nYou can't--  This is not the line for Z.X.four.  If you're going to fill out the Z.X.four, you need to have a different form of ID.\\nWhat?  I'm getting an ID.  This is why I'm here.  My wallet was stolen.\\nNo. I need another set of ID to prove this is actually you.\\nHow am I supposed to get an ID without an ID?  How does a person get an ID in the first place?\\nI don't know.  But I need an ID to pass this form along.  I can't just send it along without an ID.\\nI'm here to get an ID.\\nNo.  I need another ID, a separate one.\\nLike what?  Like a birth certificate?\\nA birth certificate, a passport...a student ID; didn't you go to school?  Anything?\\nWho the hell has a birth certificate?\\nYes but my wallet was stolen, I don't have anything.  I don't have any credit cards, I don't have my ID.  Don't you have things on file here?\\nYeah.  We keep it on file, but we need an ID to access that file.\\nThat's out of control.\\nI don't understand why this is so complicated for people when they get here.  It's just a simple form.  I just need an ID.\\nHow long have you been working here?\\nActually too long.\\nClearly.  You know, do you have like a supervisor or something?\\nYeah.  Do you want to see my supervisor?  Huh? Yeah.  Do you want to see my supervisor?  Fine.  I'll be right back.\\nThat would - I would appreciate that.  Yeah.\", 'audio_path': 'C:\\\\Users\\\\aryan\\\\Documents\\\\Study\\\\Research\\\\Audio_Output\\\\Ses01F_impro01.npy', 'video_path': 'C:\\\\Users\\\\aryan\\\\Documents\\\\Study\\\\Research\\\\Video_Output\\\\Ses01F_impro01.npy', 'label': 'Frustration'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(dataset)} scenes.\")\n",
    "print(\"Sample entry:\", dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d1d8b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_embedding import BERTFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93870573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features shape: torch.Size([4, 256, 768])\n"
     ]
    }
   ],
   "source": [
    "# Extract just the transcript texts\n",
    "texts = [item[\"transcript\"] for item in dataset]\n",
    "\n",
    "extractor = BERTFeatureExtractor()\n",
    "text_embeddings = extractor.extract_features(texts)\n",
    "\n",
    "print(\"Extracted features shape:\", text_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae250ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2167, -0.2903,  0.0502,  ...,  0.0850,  0.2398,  1.1094],\n",
      "         [ 0.5352,  0.3862,  0.2780,  ...,  0.8388,  1.1226,  0.4828],\n",
      "         [ 0.0770,  0.0631,  0.0264,  ...,  0.5759,  0.3685,  0.9782],\n",
      "         ...,\n",
      "         [ 0.6460,  0.2823,  1.1046,  ..., -0.5988, -0.5507,  0.5646],\n",
      "         [-0.1441, -0.2129, -0.3259,  ...,  0.4146,  0.1006,  0.0982],\n",
      "         [ 0.2855,  0.4230,  0.3877,  ...,  1.0782, -0.1008,  0.7047]],\n",
      "\n",
      "        [[ 0.4528,  0.0813,  0.0571,  ...,  0.0512,  0.1424,  0.4828],\n",
      "         [ 0.9556, -0.7379,  0.0470,  ...,  0.8060,  0.6914,  0.1417],\n",
      "         [ 0.0231, -0.9455,  0.8989,  ...,  0.2344,  0.3897, -0.1197],\n",
      "         ...,\n",
      "         [ 0.1216, -0.3208,  0.1883,  ...,  0.4079,  0.4873, -0.7244],\n",
      "         [ 0.5168, -0.2668,  0.1004,  ...,  0.3833,  0.2656, -0.8818],\n",
      "         [ 0.1481,  0.5754,  0.6133,  ...,  1.2368, -0.3819,  0.3198]],\n",
      "\n",
      "        [[-0.0667, -0.3416,  0.0531,  ..., -0.3352,  0.4090,  0.5171],\n",
      "         [ 0.0844, -0.6367,  0.3792,  ...,  0.5208,  1.2780,  0.6548],\n",
      "         [ 0.1942, -0.0125,  0.4636,  ...,  1.2775,  0.2558, -0.1149],\n",
      "         ...,\n",
      "         [ 0.4626,  0.1437,  1.1690,  ...,  0.0521,  0.8674, -0.0379],\n",
      "         [-1.0010, -0.9934, -0.0505,  ...,  0.8571,  0.4559, -0.5883],\n",
      "         [ 0.1857,  0.3713,  0.6616,  ...,  0.6567,  0.4442,  0.0086]],\n",
      "\n",
      "        [[ 0.3150, -0.1905,  0.3120,  ...,  0.0873,  0.3601,  0.5518],\n",
      "         [ 0.8301, -0.0536, -0.4160,  ...,  0.3257,  0.7168,  0.4618],\n",
      "         [ 0.0024, -0.5273, -0.1605,  ..., -0.0701,  0.7318,  0.2750],\n",
      "         ...,\n",
      "         [ 0.6236, -0.6064,  0.2696,  ..., -0.1838,  0.5374,  0.2427],\n",
      "         [ 0.1056, -0.5474, -0.7458,  ...,  0.6083,  0.3582,  0.3094],\n",
      "         [ 0.6187,  0.3422,  0.5747,  ...,  0.7617,  0.2976,  0.3126]]])\n"
     ]
    }
   ],
   "source": [
    "print(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc1e074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_embedding_paths = [item[\"video_path\"] for item in dataset]\n",
    "audio_embedding_paths = [item[\"audio_path\"] for item in dataset]\n",
    "video_embeddings = []\n",
    "audio_embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9120f44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded video embeddings\n",
      "\n",
      "Loaded audio embeddings\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "for path in video_embedding_paths:\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            embedding = np.load(path)\n",
    "            video_embeddings.append(embedding)\n",
    "            # print(f\"Loaded video embedding from: {path} (Shape: {embedding.shape})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading video embedding from {path}: {e}\")\n",
    "    else:\n",
    "        print(f\"Video embedding file not found: {path}\")\n",
    "print(\"\\nLoaded video embeddings\")\n",
    "\n",
    "for path in audio_embedding_paths:\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            embedding = np.load(path)\n",
    "            audio_embeddings.append(embedding)\n",
    "            # print(f\"Loaded audio embedding from: {path} (Shape: {embedding.shape})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading audio embedding from {path}: {e}\")\n",
    "    else:\n",
    "        print(f\"Audio embedding file not found: {path}\")\n",
    "print(\"\\nLoaded audio embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71da22a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully loaded 4 video embeddings.\n",
      "Successfully loaded 4 audio embeddings.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSuccessfully loaded {len(video_embeddings)} video embeddings.\")\n",
    "print(f\"Successfully loaded {len(audio_embeddings)} audio embeddings.\")\n",
    "# print(\"\\nShape of the loaded video embeddings:\", video_embeddings[0].shape)\n",
    "# print(\"Shape of the loaded audio embeddings:\", audio_embeddings[0].shape)\n",
    "\n",
    "# print(\"\\nShape of the loaded video embeddings:\", video_embeddings[1].shape)\n",
    "# print(\"Shape of the loaded audio embeddings:\", audio_embeddings[1].shape)\n",
    "\n",
    "# print(\"\\nShape of the loaded video embeddings:\", video_embeddings[2].shape)\n",
    "# print(\"Shape of the loaded audio embeddings:\", audio_embeddings[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "180b43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_embeddings = torch.from_numpy(np.stack(video_embeddings))\n",
    "audio_embeddings = torch.from_numpy(np.stack(audio_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84a9b124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1024, 768])\n",
      "torch.Size([4, 256, 768])\n"
     ]
    }
   ],
   "source": [
    "print(video_embeddings.shape)\n",
    "print(audio_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "688a0486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e57c32d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83a4a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_embedding = model.embeddings.word_embeddings(torch.tensor([tokenizer.cls_token_id]))\n",
    "sep_embedding = model.embeddings.word_embeddings(torch.tensor([tokenizer.sep_token_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6494befb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the CLS embedding: torch.Size([1, 768])\n",
      "Shape of the SEP embedding: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the CLS embedding:\", cls_embedding.shape)\n",
    "print(\"Shape of the SEP embedding:\", sep_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "312b0025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_modalities(cls_token, sep_token, video_tensor, audio_tensor, text_tensor):\n",
    "    fused = []\n",
    "    for v, a, t in zip(video_tensor, audio_tensor, text_tensor):\n",
    "        segments = [\n",
    "            cls_token,  # (1, 768)\n",
    "            v,          # (v_len, 768)\n",
    "            sep_token,  # (1, 768)\n",
    "            a,          # (a_len, 768)\n",
    "            sep_token,  # (1, 768)\n",
    "            t,          # (t_len, 768)\n",
    "            sep_token   # (1, 768)\n",
    "        ]\n",
    "        fused.append(torch.cat(segments, dim=0))  # (total_len, 768)\n",
    "\n",
    "    return fused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bb887a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_embeddings = concatenate_modalities(cls_embedding, sep_embedding, video_embeddings, audio_embeddings, text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c32c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fused_embeddings[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
